{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Strategy for Finance using LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Construction\n",
    "\n",
    "Now, we set up the TensorFlow compute graph. The deep neural network that is used in this code is comprised of a LSTM cell that runs over 10 time steps, a fully connected layers (FCL), and also drop-out layers to prevent overfitting. Calculating the number of time steps for a recurrent neural network is not a trivial task. It is actually another hyperparameter that needs to be searched. The network is depicted in the following figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/dnn.jpg\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Figure 3: Structure of the LSTM based deep neural network\n",
    "                                \n",
    "Below is the code to build the deep neural network depicted in Figure 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape): \n",
    "    initial = tf.truncated_normal(shape, stddev=0.3)\n",
    "    return tf.Variable(initial) \n",
    "    \n",
    "def bias_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.3)\n",
    "    return tf.Variable(initial) \n",
    "\n",
    "n_time_steps = 10\n",
    "def getDNN (x, LSTMCellSize, keep_prob):\n",
    "    with tf.name_scope('model'):\n",
    "        with tf.name_scope('RNN'):\n",
    "            # We will add two dropout layers and LSTM cells with the number of units as LSTMCellSize.\n",
    "            cell = rnn.DropoutWrapper(rnn.BasicLSTMCell(LSTMCellSize, forget_bias=2, activation=tf.nn.tanh), output_keep_prob=keep_prob)\n",
    "            # We use the cell to create RNN.\n",
    "            # Note that outputs is not a tensor, it is a list with one element which is numpy array. \n",
    "            outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32) \n",
    "            outputs_shape = outputs.get_shape().as_list()\n",
    "                \n",
    "        # hidden layer with sigmoid activation\n",
    "        with tf.name_scope('W_fc1'):\n",
    "            W_fc1 = weight_variable([LSTMCellSize, 1])\n",
    "        with tf.name_scope('b_fc1'):\n",
    "            b_fc1 = bias_variable([1])\n",
    "        with tf.name_scope('pred'):\n",
    "            pred = tf.matmul(outputs[:,-1,:], W_fc1) + b_fc1\n",
    "\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names that will be included in the featureset are added into colList.\n",
    "# colList will be used throughout the lab.\n",
    "colList=[]                  \n",
    "for thisColumn in df.columns: \n",
    "    if thisColumn not in ('id', 'timestamp', 'y', 'CntNs', 'y_lagged'): \n",
    "        colList.append(thisColumn)\n",
    "colList.append('y_lagged')\n",
    "\n",
    "#if you do not reset the default graph you will need to restart the kernel\n",
    "#every time this notebook is run\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network Parameters \n",
    "# Number of units in the LSTM cell.\n",
    "n_LSTMCell = len(colList)\n",
    "\n",
    "# Placeholder for the input and the keep probability for the dropout layers\n",
    "with tf.name_scope('input'):\n",
    "    x= tf.placeholder(tf.float32, shape=[None, n_time_steps, len(colList)])\n",
    "with tf.name_scope('keep_prob'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# At the input, we create 2-layer LSTM cell (with dropout layers)\n",
    "print('Building tensorflow graph')\n",
    "\n",
    "# Graph construction for the LSTM based deep neural network. \n",
    "# Structure of the network is depicted in the above figure.\n",
    "# Please see the dnn.py to see the code of the network.\n",
    "pred = getDNN (x, n_LSTMCell, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into two pieces in time to have a training and testing set. In order to have enough sample for each id, the cut-off timestamp for the training set was defined in \"insampleCutoffTimestamp\" variable as 1650. Figure 4 shows how an instrument is split in time to create training and testing set. While training the model, the training set for each instrument will be fed separately to learn the time patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/data_split.jpg\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Figure 4: Training and Testing Dataset\n",
    "    \n",
    "In the Kaggle challenge, the metric to evaluate the prediction accuracy was given as Pearson correlation. In statistics, [pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is a measure of the linear correlation between two variables X and Y. It has a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation. It is widely used in the sciences. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s.\n",
    "\n",
    "Depending on the frequency of the financial data, Pearson correlation (R) can be very small. In finance, given the high ratio of signal-to-noise, even a small R can deliver meaningful value. Please note that the algorithm that won the challenge had only 0.038 R.\n",
    "\n",
    "The following cell includes the code for creating training and testing set, and calculating Pearson correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for the output (label)\n",
    "with tf.name_scope('label'):\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 1]) \n",
    "# Placeholder to be able to split the data into training and test set while training the network.\n",
    "inSampleCutoff = tf.placeholder(tf.int32, shape = ())\n",
    "\n",
    "# this is important - we only want to train on the in-sample set of rows using TensorFlow\n",
    "y_inSample = y[0:inSampleCutoff]\n",
    "pred_inSample = pred[0:inSampleCutoff]\n",
    "\n",
    "# also extract out of sample predictions and actual values,\n",
    "# we'll use them for evaluation while training the model.\n",
    "y_outOfSample = y[inSampleCutoff:]\n",
    "pred_outOfSample = pred[inSampleCutoff:]\n",
    "\n",
    "with tf.name_scope('stats'):\n",
    "    # Pearson correlation to evaluate the model\n",
    "    covariance = tf.reduce_sum(tf.matmul(tf.transpose(tf.subtract(pred_inSample, tf.reduce_mean(pred_inSample))),tf.subtract(y_inSample, tf.reduce_mean(y_inSample))))\n",
    "    var_pred = tf.reduce_sum(tf.square(tf.subtract(pred_inSample, tf.reduce_mean(pred_inSample))))\n",
    "    var_y = tf.reduce_sum(tf.square(tf.subtract(y_inSample, tf.reduce_mean(y_inSample))))\n",
    "    pearson_corr = covariance / tf.sqrt(var_pred * var_y) \n",
    "\n",
    "tf.summary.scalar(\"pearson_corr\", pearson_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of the traditional machine learning and deep learning methods, it is assumed that the feature set and predicted value have zero mean and unit variance gaussian distribution. Empirical studies show that the financial data such as asset returns is often not compatible with this assumption. That is why we normalize the \"y\" variable by subtracting its mean and dividing the result by the standard deviation in the following cell. As an exercise, you can also normalize the features and see if you improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset is also created here. We included the code to split the data in the above cell. \n",
    "# The difference is that the above code will be used in the training by the TensorFlow.\n",
    "# This code will not be used by TensorFlow and creates the testing dataset whenever it is executed.\n",
    "dfInSample = df[df.timestamp <  insampleCutoffTimestamp]\n",
    "# create a reference dataframe (that only depends on in-sample data)\n",
    "# that gives us standard deviation and mean information on per-id basis\n",
    "# we'll use it later for variance stabilization\n",
    "meanStdById = dfInSample.groupby(['id']).agg( {'y':['mean', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the graph for training the model and see intermediate diagnostics results and the final result. We defined the important hyperparameters including the epoch, training batch size and learning rate at the top of the cell. Initially, the epoch is set to 1 because it takes 15-20 minutes to complete the training with 10 epochs even though we are using GPUs. In order to speed up the training in the lab environment, we provided pre-trained networks with 10 epochs and 20 epochs. An adaptive learning rate starting from 0.002 with exponential decay is used for the training from scratch. Learning rate should be set to 0.00058 and 0.00061 for using pre-trained models with 10 and 15 epochs respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "display_step = 100 \n",
    "epoch = 1\n",
    "pre_trained_model = 'tasks/task2/task/SavedModels/model_epoch_10.ckpt'\n",
    "mini_batch_limit = 1300\n",
    "\n",
    "# set up adaptive learning rate:\n",
    "globalStep = tf.placeholder(tf.float32)\n",
    "# Ratio of globalStep / totalDecaySteps is designed to indicate how far we've progressed in training.\n",
    "# the ratio is 0 at the beginning of training and is 1 at the end.\n",
    "# adaptiveLearningRate will thus change from the starting learningRate to learningRate * decay_rate\n",
    "# in order to simplify the code, we are fixing the total number of decay steps at 1 and pass globalStep\n",
    "# as a fraction that starts with 0 and tends to 1.\n",
    "# Learning rate should be set to 0.002 if you are training from scratch.\n",
    "# Learning rate should be set to 0.00058 if you are using the pre-trained network with 10 epochs.\n",
    "# Learning rate should be set to 0.00061 if you are using the pre-trained network with 15 epochs.\n",
    "adaptiveLearningRate = tf.train.exponential_decay(\n",
    "  0.00058,       # Start with this learning rate\n",
    "  globalStep,  # globalStep / totalDecaySteps shows how far we've progressed in training\n",
    "  1,           # totalDecaySteps\n",
    "  0.3)         # decay_rate, the factor by which the starting learning rate will be \n",
    "               # multiplied when the training is finished\n",
    "    \n",
    "# Define loss and optimizer\n",
    "# Note the loss only involves in-sample rows\n",
    "# Regularization is added in the loss function to avoid over-fitting\n",
    "rnn_variables = lstm_variables = [v for v in tf.trainable_variables()\n",
    "                    if v.name.startswith('rnn')]\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.nn.l2_loss(tf.subtract(y_inSample,pred_inSample)) + tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(scale=0.0001), tf.trainable_variables())\n",
    "\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=adaptiveLearningRate).minimize (loss) \n",
    "\n",
    "# Getting unique ids to train the network per id basis.\n",
    "ids = df.id.unique()\n",
    "ids.sort()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "# initialize the variables \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "totalActual = []\n",
    "totalPredicted = []\n",
    "import random\n",
    "# Launch the graph \n",
    "# Implement Cross Validation, but in a vay that preserves temporal structure for id's \n",
    "with tf.Session() as sess:  \n",
    "    # Global variables are initialized\n",
    "    sess.run(init) \n",
    "    \n",
    "    # Restore latest checkpoint\n",
    "    model_saver = tf.train.Saver()\n",
    "    model_saver.restore(sess, pre_trained_model)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"tasks/tensorboard/logs\", graph=tf.get_default_graph())\n",
    "    step = 50  \n",
    "    writer_step = 1;\n",
    "    for i in range(epoch):\n",
    "        print('Epoch: ', i, '******************************')        \n",
    "        actual = []\n",
    "        predicted = []\n",
    "        \n",
    "        random.shuffle(ids)\n",
    "\n",
    "        for thisId in ids:\n",
    "            # Getting the data of the current id\n",
    "            this_df = df[df.id == thisId].copy()\n",
    "            this_df = this_df.sort_values(['id', 'timestamp'])\n",
    "                        \n",
    "            # we need to pass training set to the graph definition\n",
    "            # optimization will only consider in training set\n",
    "            inSampleSize, _ = this_df[this_df.timestamp < insampleCutoffTimestamp].shape\n",
    "            totalRows, _ = this_df.shape\n",
    "            \n",
    "            batch_y = this_df.loc[:,'y'].values            \n",
    "            batch_x = this_df[colList].values\n",
    "                    \n",
    "            if totalRows < n_time_steps:\n",
    "                continue\n",
    "\n",
    "            # Data is formated as a 3D tensor with the shape of (batch_size, n_time, n_feature) for LSTM\n",
    "            # n_time_steps parameter determines how many steps that LSTM will unroll in time\n",
    "            complete_x = np.zeros([totalRows-n_time_steps+1, n_time_steps, len(colList)])\n",
    "            for n in range(n_time_steps):\n",
    "                complete_x[:,n,:]=batch_x[n:totalRows-n_time_steps+n+1,:]\n",
    "            \n",
    "            batch_y = batch_y[n_time_steps-1:]\n",
    "            inSampleSize -= n_time_steps - 1\n",
    "\n",
    "            # variance stabilizing transform\n",
    "            # some id's will not have in-sample rows, we cannot perform transform on those\n",
    "            # furthermore, since there is not in-sample rows to train on, we must skip\n",
    "            if inSampleSize < 10:\n",
    "                continue\n",
    "                \n",
    "            # perform variance stabilization\n",
    "            thisMean = meanStdById.loc[thisId][0]\n",
    "            thisStd = meanStdById.loc[thisId][1]\n",
    "            batch_y = (batch_y - thisMean) / thisStd\n",
    "            \n",
    "            batch_y = batch_y.reshape(-1,1)\n",
    "            minibatchSize, _ = batch_y.shape\n",
    "\n",
    "            # we want to make sure that RNN reaches steady state\n",
    "            if minibatchSize < mini_batch_limit: \n",
    "                continue \n",
    "            \n",
    "            # Run optimization \n",
    "            # note: keep_prob is set to 0.5 for training only!\n",
    "            _, currentRate = sess.run([optimizer, adaptiveLearningRate], feed_dict={x: complete_x, y: batch_y, keep_prob:0.5, inSampleCutoff:inSampleSize, globalStep:i/epoch})\n",
    "\n",
    "            # Obtain out of sample target variable and our prediction\n",
    "            y_oos, pred_oos = sess.run([y_outOfSample, pred_outOfSample], feed_dict={x: complete_x, y: batch_y, keep_prob:1.0, inSampleCutoff:inSampleSize}) \n",
    "            \n",
    "            # flatten the returned lists\n",
    "            y_oos = [y for x in y_oos for y in x]\n",
    "            pred_oos = [y for x in pred_oos for y in x]\n",
    "            \n",
    "            #reverse transform before recording the results\n",
    "            if inSampleSize:            \n",
    "                y_oos = [ (t*thisStd + thisMean) for t in y_oos]\n",
    "                pred_oos = [ (t*thisStd + thisMean) for t in pred_oos]\n",
    "            \n",
    "            # record the results\n",
    "            actual.extend(y_oos)\n",
    "            predicted.extend(pred_oos)\n",
    "                       \n",
    "            totalActual.extend(y_oos)\n",
    "            totalPredicted.extend(pred_oos)\n",
    "            \n",
    "            # Once every display_step show some diagnostics - the loss function, in-sample correlation, etc.\n",
    "            if step % display_step == 0: \n",
    "                # Calculate batch accuracy \n",
    "                # Calculate batch loss \n",
    "                correl, lossResult, summary = sess.run([pearson_corr, loss, summary_op], feed_dict={x: complete_x, y: batch_y, keep_prob:1.0, inSampleCutoff:inSampleSize})\n",
    "                \n",
    "                writer.add_summary(summary, writer_step)\n",
    "                writer_step += 1\n",
    "                # corrcoef sometimes fails to compute correlation for a perfectly valid reason (e.g. stdev(pred_oos) is 0)\n",
    "                # it sets the result to nan, but also gives an annoying warning\n",
    "                # the following suppresses the warning\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    correl_oos = np.corrcoef(y_oos, pred_oos)[0,1]\n",
    "                    \n",
    "                print('LR: %s - Iter %s, minibatch loss = %s, minibatch corr = %s, oos %s (%s/%s)' % (currentRate, step, lossResult, correl, correl_oos, inSampleSize, totalRows))\n",
    "                \n",
    "            step += 1 \n",
    "       \n",
    "        print('Optimization Finished!') \n",
    "        print('Correl: ', np.corrcoef(actual, predicted)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes 3-5 minutes to complete the training with 1 epochs. We also provided TensorBoard to review the model architecture, loss and correlation variables. TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. \n",
    "\n",
    "### Click [here](/tensorboard/) to start TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a correlation value around R = 0.04. Note that the correlation tends to increase with each epoch (but not always). \n",
    "\n",
    "Let's use the pre-trained model with 15 epochs by setting the pre_trained_model variable as **pre_trained_model = '/tasks/task2/task/SavedModels/model_epoch_15.ckpt'** in above cell, lower the starting Learning Rate to **0.00061** and re-run everything using Kernel->Restart & Run All.\n",
    "\n",
    "What is the correlation that you get this time? Was it improved?\n",
    "\n",
    "Since training takes significant amount of time, we recommend you train the model with 20 epochs and check the correlation after this lab in your environment. You should get a correlation value around R = 0.05.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
