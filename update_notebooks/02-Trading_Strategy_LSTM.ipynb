{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Strategy for Finance using LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Configurations and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server. First, we import several widely used modules such as NumPy for numerical calculations, pandas for data management, matplotlib for visualizations, and TensorFlow for building and training deep neural networks.\n",
    "\n",
    "**Environment Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import h5py\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pprint as pp \n",
    "import tensorflow as tf \n",
    "from tensorflow.contrib import rnn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import prepareData as prepData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)\n",
    "MAX_SEQUENCE_LENGTH = 32\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "print(\"Keras version:\",keras.__version__)\n",
    "print(\"Tensorflow version:\",tf.__version__)\n",
    "print(\"Sklearn version:\",sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical DL workflow starts with data preparation because the data is not clean and ready to use most of the time. Deep neural network building and training follow the data preparation. Lastly, the trained network is validated with a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data needs to be cleaned before training the network. Since cleaning the data takes significant amount of time (around 20 minutes), we have stored the cleaned data into another .h5 file. If you would like to use the original data and run the cleaning code, please set the \"usePreparedData\" variable to \"False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSeq2Seq  big_lstm  build_imagenet_data  cnn  tftrt\n"
     ]
    }
   ],
   "source": [
    "!tar -czf examples.tar.gz /workspace/nvidia-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is prepared and stored in a seperate .h5 file.\n",
    "# Set usePreparedData = False to use the original data and run the data preparation code\n",
    "usePreparedData = True\n",
    "# insampleCutoffTimestamp variable is used to split the data in time into two pieces to create training and test set.\n",
    "insampleCutoffTimestamp = 1650\n",
    "\n",
    "# If usePreparatedData is True, then the prepared data is stored. Otherwise, the original data is stored\n",
    "if usePreparedData == True:\n",
    "    #with pd.HDFStore(\"/home/mimas/2sigma/DLI_FSI/2sigma/train_prepared.h5\", 'r') as train:\n",
    "    with pd.HDFStore(\"data/algo_trading/trainDataPrepared.h5\", 'r') as train:\n",
    "        df = train.get(\"train\") \n",
    "else:\n",
    "    with pd.HDFStore(\"data/algo_trading/train.h5\", 'r') as train:\n",
    "        df = train.get(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple instruments in the dataset and each instrument has an id. Time is represented by the 'timestamp' feature. Let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the original data is stored, the data preparation code will be executed in the following cell. First, extreme values in each feature set are removed. Then, some hand-crafted features are added to feature set to boost the prediction accuracy. There are many methods including PCA and auto-encoders to do the feature engineering rather than creating hand-crafted features. As an exercise, we highly recommend you to add auto-encoders to the code and check the accuracy after the lab. Lastly, NaNs are replaced with the median of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if usePreparedData == False:\n",
    "    # Original data is not clean and some the samples are a bit extreme.\n",
    "    # These values are removed from the feature set.\n",
    "    df = prepData.removeExtremeValues(df, insampleCutoffTimestamp)\n",
    "    # A little bit feature engineering. Hand-crafted features are created here to boost the accuracy.\n",
    "    df = prepData.createNewFeatures(df) \n",
    "    # Check whether ve still have any NaNs \n",
    "    df = prepData.fillNaNs(df) \n",
    "    df.to_hdf(\"data/algo_trading/trainDataPrepared.h5\", 'train')\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
